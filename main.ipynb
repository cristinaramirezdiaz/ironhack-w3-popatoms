{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop atoms\n",
    "Let's find the musical atoms that make up the most popular hits of the last decades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare the audio features of the most popular songs of before 1962 (before the Beatles era), with a more general sample of popular songs from the 60's to current time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular before The Beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the Billboard data.\n",
    "# Billboard collects the most popular songs weekly since 1958. This is the data we will use for this project.\n",
    "# The API may fail, so to avoid having to repeat queries, we save the data continuously int a csv (\"df_ranks_weekly.csv\")\n",
    "\n",
    "recalculate = False\n",
    "\n",
    "if recalculate:\n",
    "\n",
    "    if exists(\"df_ranks_weekly_temp.csv\"):\n",
    "        temp_csv_path = \"df_ranks_weekly.csv\"\n",
    "    else:\n",
    "        temp_csv_path = \"\"\n",
    "        \n",
    "    df_ranks_weekly = create_weekly_ranks_df(\"1958-01-01\", \"1961-12-31\", csv_path = temp_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get peak values. \n",
    "# Some songs are listed more than once, as they come up several times in the charts for different weeks. \n",
    "# We will only keep one entry for each song, calculate the peak position, maximum number of weeks on the chart, and date that peak position was reached for each song.  \n",
    "\n",
    "if not exists(\"df_songs_60.csv\"):    \n",
    "\n",
    "#   Load the billboard ranks data\n",
    "    df_ranks_weekly = pd.read_csv(\"df_ranks_weekly.csv\")\n",
    "\n",
    "    df_songs_60 = calculate_ranks_peaks(df_ranks_weekly)\n",
    "\n",
    "    # Save the cleaned data to a CSV file.\n",
    "    df_songs_60.to_csv(\"df_songs_60.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get audio analysis data from Spotify.\n",
    "# ! Beware: DO NOT re-execute this query unless you absolutely have to. Spotify may block your API key for a while.  \n",
    "\n",
    "if not exists(\"df_audio_analysis_60.csv\"):\n",
    "\n",
    "    # Load the cleaned data\n",
    "    df_songs_60 = pd.read_csv(\"df_songs_60.csv\")\n",
    "\n",
    "    # add audio analysis columns\n",
    "    audio_analysis_df = create_audio_analysis_df(df_songs_60)\n",
    "\n",
    "    # Save the cleaned data to a CSV file.\n",
    "    audio_analysis_df.to_csv(\"df_audio_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular of all time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We asked GPT for a list of songs that represent the greatest hits from year to year since 1960. \n",
    "# The result was stored in a csv file \"df_songs_sample.csv\"\n",
    "\n",
    "df_songs_sample = pd.read_csv(\"df_songs_sample.csv\")\n",
    "\n",
    "# we need to melt the dataframe to have one column for years, one column for titles, and one column for the artist name. \n",
    "df_songs_sample = df_songs_sample.melt(var_name='peak_year', value_name='title')\n",
    "df_songs_sample[\"artist\"] = df_songs_sample[\"title\"].str.split(\" - \").str[0]\n",
    "df_songs_sample[\"title\"] = df_songs_sample[\"title\"].str.split(\" - \").str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now query these songs from spotify. \n",
    "# ! Beware: DO NOT re-execute this query unless you absolutely have to. Spotify may block your API key for a while.  \n",
    "\n",
    "if not exists(\"df_audio_analysis_sample.csv\"):\n",
    "    df_audio_analysis_sample = create_audio_analysis_df(df_songs_sample)\n",
    "\n",
    "    # Save the cleaned data to a CSV file.\n",
    "    df_audio_analysis_sample.to_csv(\"df_audio_analysis_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular before The Beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csvs\n",
    "aax_60 = pd.read_csv(\"df_audio_analysis_60.csv\")\n",
    "aax_sample = pd.read_csv(\"df_audio_analysis_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 819 entries, 0 to 818\n",
      "Data columns (total 23 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   title             819 non-null    object \n",
      " 1   artist            819 non-null    object \n",
      " 2   weeks             819 non-null    float64\n",
      " 3   peak_rank         819 non-null    float64\n",
      " 4   peak_date         819 non-null    object \n",
      " 5   id                819 non-null    object \n",
      " 6   title_spotify     819 non-null    object \n",
      " 7   album             819 non-null    object \n",
      " 8   sp_popularity     819 non-null    float64\n",
      " 9   colab             819 non-null    object \n",
      " 10  release_date      819 non-null    object \n",
      " 11  danceability      819 non-null    float64\n",
      " 12  energy            819 non-null    float64\n",
      " 13  loudness          819 non-null    float64\n",
      " 14  speechiness       819 non-null    float64\n",
      " 15  acousticness      819 non-null    float64\n",
      " 16  instrumentalness  819 non-null    float64\n",
      " 17  liveness          819 non-null    float64\n",
      " 18  valence           819 non-null    float64\n",
      " 19  key               819 non-null    float64\n",
      " 20  mode              819 non-null    float64\n",
      " 21  tempo             819 non-null    float64\n",
      " 22  duration          819 non-null    float64\n",
      "dtypes: float64(15), object(8)\n",
      "memory usage: 147.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's explore the 58-60s data\n",
    "aax_60.duplicated(subset=['title', 'artist']).sum()\n",
    "aax_60.info()\n",
    "\n",
    "# in the data from the years before 1960, there are no null values. \n",
    "# All the data types seem correct.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular of all time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_spotify</th>\n",
       "      <th>title</th>\n",
       "      <th>peak_year</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>I Will Always Love You</td>\n",
       "      <td>I Will Always Love You</td>\n",
       "      <td>1975</td>\n",
       "      <td>Whitney Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>I Will Always Love You</td>\n",
       "      <td>I Will Always Love You</td>\n",
       "      <td>1993</td>\n",
       "      <td>Whitney Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>2021</td>\n",
       "      <td>The Weeknd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>2024</td>\n",
       "      <td>The Weeknd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Shoop</td>\n",
       "      <td>Shoop</td>\n",
       "      <td>1991</td>\n",
       "      <td>Salt-N-Pepa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Shoop</td>\n",
       "      <td>Shoop</td>\n",
       "      <td>1994</td>\n",
       "      <td>Salt-N-Pepa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Twist</td>\n",
       "      <td>The Twist</td>\n",
       "      <td>1960</td>\n",
       "      <td>Chubby Checker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Twist</td>\n",
       "      <td>The Twist</td>\n",
       "      <td>1962</td>\n",
       "      <td>Chubby Checker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Theme from \"A Summer Place\"</td>\n",
       "      <td>Theme from A Summer Place</td>\n",
       "      <td>1960</td>\n",
       "      <td>Percy Faith &amp; His Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Theme from \"A Summer Place\"</td>\n",
       "      <td>Theme from A Summer Place</td>\n",
       "      <td>1961</td>\n",
       "      <td>Percy Faith &amp; His Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>You Oughta Know - 2015 Remaster</td>\n",
       "      <td>You Oughta Know</td>\n",
       "      <td>1995</td>\n",
       "      <td>Alanis Morissette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>You Oughta Know - 2015 Remaster</td>\n",
       "      <td>You Oughta Know</td>\n",
       "      <td>1996</td>\n",
       "      <td>Alanis Morissette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title_spotify                      title  peak_year  \\\n",
       "77            I Will Always Love You     I Will Always Love You       1975   \n",
       "166           I Will Always Love You     I Will Always Love You       1993   \n",
       "306                  Save Your Tears            Save Your Tears       2021   \n",
       "322                  Save Your Tears            Save Your Tears       2024   \n",
       "158                            Shoop                      Shoop       1991   \n",
       "174                            Shoop                      Shoop       1994   \n",
       "2                          The Twist                  The Twist       1960   \n",
       "10                         The Twist                  The Twist       1962   \n",
       "3    The Theme from \"A Summer Place\"  Theme from A Summer Place       1960   \n",
       "6    The Theme from \"A Summer Place\"  Theme from A Summer Place       1961   \n",
       "179  You Oughta Know - 2015 Remaster            You Oughta Know       1995   \n",
       "184  You Oughta Know - 2015 Remaster            You Oughta Know       1996   \n",
       "\n",
       "                          artist  \n",
       "77               Whitney Houston  \n",
       "166              Whitney Houston  \n",
       "306                   The Weeknd  \n",
       "322                   The Weeknd  \n",
       "158                  Salt-N-Pepa  \n",
       "174                  Salt-N-Pepa  \n",
       "2                 Chubby Checker  \n",
       "10                Chubby Checker  \n",
       "3    Percy Faith & His Orchestra  \n",
       "6    Percy Faith & His Orchestra  \n",
       "179            Alanis Morissette  \n",
       "184            Alanis Morissette  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the sample data\n",
    "\n",
    "aax_sample.duplicated(subset=['title', 'artist']).sum()\n",
    "aax_sample.loc[aax_sample.duplicated(subset=['title', 'artist'], keep=False), ['title_spotify', 'title', 'peak_year', 'artist']].sort_values(by=['title', 'artist'])\n",
    "# there are 6 repeated values in the sample data. Most of them look ok (some songs can reach a popularity peak in multiple years).\n",
    "# But there's one particular data point that looks  mistaken: the song \"I Will Always Love You\" by Whitney Houston wasn't released in 1975. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# We will remove the mistaken value and filter the first peak date for the rest of duplicates.\n",
    "aax_sample = aax_sample[~((aax_sample.title==\"I Will Always Love You\") & (aax_sample.peak_year==1975))]\n",
    "aax_sample.drop_duplicates(subset=['title', 'artist'], keep='first', inplace=True)\n",
    "\n",
    "aax_sample.duplicated(subset=['title', 'artist']).sum() #there are no more duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title_spotify', 'album', 'sp_popularity', 'artist', 'colab',\n",
      "       'release_date', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
      "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
      "       'valence', 'tempo', 'duration', 'peak_year', 'title'],\n",
      "      dtype='object')\n",
      "Index(['title', 'artist', 'weeks', 'peak_rank', 'peak_date', 'id',\n",
      "       'title_spotify', 'album', 'sp_popularity', 'colab', 'release_date',\n",
      "       'danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
      "       'instrumentalness', 'liveness', 'valence', 'key', 'mode', 'tempo',\n",
      "       'duration'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We want to make sure that the datasets are comparable and use the same column names. \n",
    "\n",
    "print(aax_sample.columns)\n",
    "print(aax_60.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will:\n",
    "# * calculate \"peak_year\" from peak_date in the 60s dataset: \n",
    "aax_60['peak_year'] = pd.to_datetime(aax_60['peak_date']).dt.year\n",
    "\n",
    "# * add \"lustrum_year\" to group songs by lustrum later in the analysis:\n",
    "aax_60['lustrum'] = (aax_60['peak_year'] // 5 * 5).astype(str) + '-' + ((aax_60['peak_year'] // 5 * 5) + 4).astype(str)\n",
    "aax_sample['lustrum'] = (aax_sample['peak_year'] // 5 * 5).astype(str) + '-' + ((aax_sample['peak_year'] // 5 * 5) + 4).astype(str)\n",
    "\n",
    "\n",
    "# * sort the columns to make df easier to compare and humanly readable: \n",
    "aax_sample = aax_sample.reindex(['title', 'title_spotify','artist', 'album', 'colab', \n",
    "                           'release_date', 'peak_year', 'lustrum', 'sp_popularity', \n",
    "                           'tempo', 'duration','key',  'mode', \n",
    "                           'danceability', 'energy', 'loudness','speechiness', 'acousticness', 'instrumentalness', 'liveness','valence'], axis = 1)\n",
    "\n",
    "aax_60 = aax_60.reindex(['title', 'title_spotify', 'artist', 'album', 'colab', 'id', \n",
    "                       'release_date', 'peak_rank', 'peak_date', 'peak_year', 'lustrum', 'weeks', 'sp_popularity', \n",
    "                       'tempo', 'duration', 'key', 'mode', \n",
    "                       'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can now combine de df: \n",
    "aax_combined = pd.concat([aax_60, aax_sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a column to check if the song was popular before 1964:\n",
    "aax_combined[\"before_1964\"] = aax_combined[\"peak_year\"] < 1964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We clean and format the release date column and calculate the release year:\n",
    "\n",
    "aax_combined['release_date'] = aax_combined['release_date'].apply(parse_dates)\n",
    "aax_combined['release_date'] = aax_combined['release_date'].apply(lambda x: parse_years(x) if pd.isna(pd.to_datetime(x, errors='coerce')) else pd.to_datetime(x, errors='coerce'))\n",
    "\n",
    "aax_combined = aax_combined.dropna(subset=['release_date'])\n",
    "aax_combined['release_year'] = aax_combined['release_date'].dt.year\n",
    "\n",
    "aax_combined.to_csv(\"df_aax_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We canculate de release year for later analysis: \n",
    "aax_combined['release_date'] = pd.to_datetime(aax_combined['release_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by analysis the evolution of different parameters over time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the combined df\n",
    "aax_combined = pd.read_csv(\"df_aax_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `year` for `x`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot line charts of popularity: \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplot_year_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maax_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpopularity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot line charts of different acoustic parameters:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plot_year_mean(aax_combined, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macousticness\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Code/ironhack_projects/w3-popatoms/functions.py:255\u001b[0m, in \u001b[0;36mplot_year_mean\u001b[0;34m(df, params, type, year_column, figsize, grid)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m--> 255\u001b[0m         \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myear_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Configurar la grÃ¡fica\u001b[39;00m\n\u001b[1;32m    258\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(params)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mean per year\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/Code/.venv/lib/python3.12/site-packages/seaborn/relational.py:485\u001b[0m, in \u001b[0;36mlineplot\u001b[0;34m(data, x, y, hue, size, style, units, weights, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlineplot\u001b[39m(\n\u001b[1;32m    472\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    473\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# Handle deprecation of ci parameter\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     errorbar \u001b[38;5;241m=\u001b[39m _deprecate_ci(errorbar, ci)\n\u001b[0;32m--> 485\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_LinePlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrorbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrorbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_hue(palette\u001b[38;5;241m=\u001b[39mpalette, order\u001b[38;5;241m=\u001b[39mhue_order, norm\u001b[38;5;241m=\u001b[39mhue_norm)\n\u001b[1;32m    496\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_size(sizes\u001b[38;5;241m=\u001b[39msizes, order\u001b[38;5;241m=\u001b[39msize_order, norm\u001b[38;5;241m=\u001b[39msize_norm)\n",
      "File \u001b[0;32m~/Code/.venv/lib/python3.12/site-packages/seaborn/relational.py:216\u001b[0m, in \u001b[0;36m_LinePlotter.__init__\u001b[0;34m(self, data, variables, estimator, n_boot, seed, errorbar, sort, orient, err_style, err_kws, legend)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    204\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, variables\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_size_range \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    213\u001b[0m         np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlines.linewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    214\u001b[0m     )\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;241m=\u001b[39m estimator\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrorbar \u001b[38;5;241m=\u001b[39m errorbar\n",
      "File \u001b[0;32m~/Code/.venv/lib/python3.12/site-packages/seaborn/_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Code/.venv/lib/python3.12/site-packages/seaborn/_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m~/Code/.venv/lib/python3.12/site-packages/seaborn/_core/data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     data: DataSource,\n\u001b[1;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[1;32m     55\u001b[0m ):\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[0;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n",
      "File \u001b[0;32m~/Code/.venv/lib/python3.12/site-packages/seaborn/_core/data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn entry with this name does not appear in `data`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `year` for `x`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot line charts of popularity: \n",
    "\n",
    "plot_year_mean(aax_combined, type=\"line\", params=['popularity'])\n",
    "\n",
    "# Plot line charts of different acoustic parameters:\n",
    "plot_year_mean(aax_combined, type=\"line\", params=['acousticness'])\n",
    "plot_year_mean(aax_combined, type=\"line\", params=['danceability'])\n",
    "plot_year_mean(aax_combined, type=\"line\", params=['energy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
